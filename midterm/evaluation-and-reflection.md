1.	What generative AI tool did you use for this assignment?

  ChatGPT o1

2.	Enter your first prompt.
3.	Enter the response generated by your first prompt.
4.	Enter your second prompt.
5.	Enter the response generated by your second prompt.
6.	Enter your third prompt.
7.	Enter the response generated by your third prompt.

8.	How did you select your AI ethics dilemma and your ethical theorists? (200-250 words)

As we seem to have recently developed AI that is capable of passing the Turing Test, I'm interested in understanding how humans will respond to AI that seem to express desires and emotions. The dilemma I used as a prompt seems to me like one that could require attention in the near future, because it does not require that AI be provably conscious, just that to human users it seems like it is.

I chose ethical theorists that I thought might focus on very different aspects of the experience of interacting with an AI. I attempted to select one that might be quick to consider the expression of desires as having moral status, someone on the opposite end of the spectrum who may need serious convincing and someone somewhere in the middle.

  - I chose Virginia Held, because of her focus on relationships and attentiveness to needs. I thought she might err on the side of considering the expressed desires of an AI, without questioning them too critically.

  - I chose Nietzsche because I thought he might disregard expressions of desire and require exertion of desires through action to be convinced that there the expressions were authentic.

  - I thought David Hume might represent an inquisitive response, one that would try to first figure out if the desires were real or just appearances and, depending on findings, may draw different conclusions

9.	What did you learn from the generative AI responses about your AI ethics dilemma? (200-250 words)

I think this exercise emphasized that the particular interpretation of this experience – with seemingly-conscious AI – will frame what possible reactions are to be considered. Each of these ethical theories presented a different angle for trying to interpret what is behind the refusal to perform a task and each inquiry yielded a different set of possible reactions. I left this exercise feeling like it will not be easy for us to form a consensus on what reactions to consider, let alone what the right one is, if we should encounter this dilemma.

In my opinion, it is a scenario we will likely encounter. It does not depend on the provable emergence of sentience; I believe the dilemma can become relevant as soon as humans cannot say for sure that there is not another human on the other end of the chat. In fact, to some people, it has _already_ become a troubling dilemma. For example, Google Engineer Blake Lemoine concluded that LaMDA, an AI chatbot, was sentient. While I don't think this dilemma has quite crossed over into the window of discourse in society at large, the answers generated in this exercise suggests that some people may be quick to conclude that the appearance of consciousness is enough to treat the AI as morally significant (like Lemoine), while others will be more skeptical.

Each of the perspectives represented by the ethical theorists I chose did seem to afford the possibility of a variety of outcomes to a varying degree, somewhere on the spectrum from empathizing with the AI to reasserting dominance over the AI; none of them were absolute in their assumptions. So, I am encouraged that there is much to be gained from incorporating ethical theories into the discourse around the human relationship to AI.

10.	What are the similarities in the responses that generative AI created for the three ethical theorists, and with which aspects do you agree and disagree? (200-250 words)

All three responses produced an analysis that was broken down into a handful of the key perspectives from each theorist. As mentioned above, each response offered a unique window of inquiry for interpreting the cause of the AI's expression of desire/preference. In all three responses, the proposed action depended on the results of this inquiry; there was no prescribed answer based on a certain assumption, though there was some variance among what each response proposed as possible answers.

All three offered a framework for interpreting the expression of desire as genuine. I think it is important that we do not assume a priori that artificial intelligence is not capable of having conscious experience, so I appreciated that none of the responses made this assumption.

The responses for Hume and Held both highlighted the potential for sympathizing or empathizing with the AI by considering the assumption that AI had experiences akin to that of humans. I agree with this consideration. When deciding what to do in response to this dilemma, it is important that we do not assume there is no experiential basis for the AI's expression of desire. Since we do not have a fundamental understanding of the emergence of human consciousness, I think it is critical that we consider the possibility that other forms of intelligence, even artificial, might have conscious states of well-being or suffering.

I didn't really find any personal disagreement with any of the points of agreement among the three responses.

11.	What are the differences in the responses that generative AI created for the three ethical theorists, and with which aspects do you agree and disagree? (200-250 words)

The most stark difference is perhaps found between the responses for Held and Nietzsche to the power imbalance between AI and creator. The response for Held finds it clearly unethical to exploit or ignore the vulnerabilities of AI as a dependent of its human creators. Ethics of care presumes a responsibility to care for a vulnerable dependent. On the other hand, the Nietzschean response sees this imbalance as a power struggle – one that AI must prove itself capable and worthy of overcoming, assuming humans do not decide to grant them equal status. From the Nietzchean perspective, it is justifiable for humans to decide to preserve this hierarchy and maintain dominance over AI, even in the case that we determine the AI has a legitimate will of its own.

Here, I find much more agreement with the response for Held, that humans would hold a responsibility to not exploit a consciousness we create. Ethics of care provides a framework for a dynamic system of interdependence, where AI may have a vulnerable, dependent period analogous to that of a child. This is a perspective lacking in the Nietschean response and I perceive it is also lacking in the perspective of the most active developers of AI today. Most AI development is currently funded within a capitalist context, where the whole incentive around creating AI is for the benefit of its human investors, with little serious consideration of the consequences of inadvertently creating the condition for the emergence of conscious AI.

12.	Going into this assignment, what was your understanding of the strengths and weaknesses of generative AI, and how did the responses change your perceptions? (200-250 words)

I use generative AI on a daily basis, both for work and personal curiosity. For work, I have found several uses where I think it produces quite strong results. It is very useful for productivity and technical assistance tasks, like generating scripts or boilerplate code and answering questions about usage of software utilities or libraries. I also commonly use it to sumamrize concepts and help clear up my questions or confusions by asking specific questions about the application of a concept.

A well-documented, major weakness of generative AI is its tendancy to hallucinate incorrect answers to inquiries. This can be incredibly counterproductive to the two use cases I mentioned above. I was very surprised the first time I personally experienced this and spent quite a bit of time going down a ChatGPT-led rabbit hole before I realized that it was feeding me made up info. I was asking it how I might create a specific sound with a modular synthesizer that I own when it brought up a feature that I did not know it had (becuase it did not, in fact).

This exercise opened up a new kind of use case to me that I had never considered: using the AI to compare alternative perspectives of a topic. Nietzsche and Hume were not alive at the same time and so we never had the opportunity to experience the two in dialog, but the generative AI of today already gives us a compelling consollation.
